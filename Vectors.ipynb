{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheatsheet 1. Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cheatsheet covers vectors only. Matrices will be covers in a separate notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "(clickable is saved as HTML or downloades as .ibynb)  \n",
    "- [Definitions](#vectors)\n",
    "- [Vector Operations](#vecop)\n",
    "- [Vector Norm](#vecnorm)\n",
    "- [Dot Product](#dotproduct)\n",
    "- [Outer Product](#outerproduct)\n",
    "- [Vectors with Complex Numbers](#complexvectors)\n",
    "- [Spaces and Subspaces](#spaces)\n",
    "- [Span](#span)\n",
    "- [Linear Independence](#linindep)\n",
    "- [Basis](#basis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vectors\"></a>\n",
    "# Defintions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector - an ordered list of numbers. Typical notations for the vector: \n",
    "$$\\vec{v}, \\boldsymbol{v}$$\n",
    "In this cheatsheet the vectors will be written as simple lowercase letters - e.g., $a$, $b$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometrically a vector specifies the direction. Standard position is when the tail is at the origin.   \n",
    "<b>IMPORTANT</b>: In Liner Algebra a vector is assumed to be a column vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vecop\"></a>\n",
    "# Basic Vector Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Vector addition:  \n",
    "    - Geometrically: plact tail of one vector to the head of the other and connect. \n",
    "    - Algebraically: add elementwise \n",
    "- Scalar multiplication:   \n",
    "    - Scalar is typically denoted by some lowercase Greek letter: $\\alpha, \\beta, \\lambda$\n",
    "    - Scalar multiplication never changes the direction of a vector (it can reverse it, when $\\lambda < 0$, but the direction is considered to be the same - the angle doesn't change!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vecnorm\"></a>\n",
    "# Vector Norm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector magnitude (vector norm) can be calculated from the Pythagorean Theorem which can be expressed using dot product: \n",
    "$$\\lVert{\\vec{v}}\\rVert = \\sqrt{\\vec{v}^T \\vec{v}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In Python:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.58257569495584"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "v = [1, 2, -4]\n",
    "np.linalg.norm(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dotproduct\"></a>\n",
    "# Dot Product (Inner Product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot Product - single number that provides information about the relation between the vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\alpha = a \\cdot b = <a,b> = a^T b = \\sum_{i=1}^{n}a_i b_i = \\lVert a \\rVert \\lVert b \\rVert \\cos{\\theta_{ab}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>In Python:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Important note</b>: $a^T b = b^T a$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dot product is only defined for the vectors of the same length (for obvious reasons). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this equation we can also find the angle between any two vectors:\n",
    "\n",
    "$$\\cos \\theta_{ab} = {\\frac{\\alpha}{\\lVert a \\rVert \\lVert b \\rVert}}$$\n",
    "\n",
    "$$\\theta_{ab} = \\arccos \\Big({\\frac{\\alpha}{\\lVert a \\rVert \\lVert b \\rVert}}\\Big)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to calculate dot product is as the product of vector norms scaled by the cosine of the angle between them:\n",
    "\n",
    "$$\\alpha = \\lVert a \\rVert \\lVert b \\rVert \\cos{\\theta_{ab}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The angle (or just the value of cosine) gives us the information about the angle between the vectors. There are four cases possible: \n",
    "\n",
    "1) $\\cos \\theta > 0 \\implies \\alpha > 0$, acute angle  \n",
    "2) $\\cos \\theta < 0 \\implies \\alpha < 0$, obtuse angle  \n",
    "3) $\\cos \\theta = 0 \\implies \\alpha = 0$, orthogonal   \n",
    "4) $\\cos \\theta = 1 \\implies \\alpha = \\lVert a \\rVert \\lVert b \\rVert$, collinear "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proof for the dot product\n",
    "We start with The Law of Cosines: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\lVert a - b \\rVert}^2 = {\\lVert a \\rVert}^2 + {\\lVert b \\rVert}^2 - 2 {\\lVert a \\rVert} {\\lVert b \\rVert} \\cos \\theta_{ab} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note: if $\\theta_{ab} = 90$, we get standard Pythagorean theorem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's write out the norm using the definitions for the dot product: \n",
    "\n",
    "$${\\lVert a - b \\rVert}^2 = (a-b)^T (a-b) = a^T a - a^T b - b^T a + b^T b = \\\\ = a^T a - a^T b - a^T b + b^T b = \n",
    "a^T a - 2 a^T b + b^T b $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can equate these two parts: \n",
    "$${\\lVert a \\rVert}^2 + {\\lVert b \\rVert}^2 - 2 {\\lVert a \\rVert} {\\lVert b \\rVert} \\cos \\theta_{ab} = a^T a - 2 a^T b + b^T b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reminder: ${\\lVert v \\rVert}^2 = v^T v$, so these terms cancel out, as well as -2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\lVert a \\rVert} {\\lVert b \\rVert} \\cos \\theta_{ab} =  a^T b$$\n",
    "QED\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"outerproduct\"></a> \n",
    "       \n",
    "# Outer Product "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlinke inner product, outer product produces a matrix and is denoted as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v w^T$$\n",
    "Reminder, $v$ and $w$ are column vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "3\\\\\n",
    "4\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a&b&c&d\\\\\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "1a&1b&1c&1d\\\\\n",
    "2a&2b&2c&2d\\\\\n",
    "3a&3c&3c&3d\\\\\n",
    "4a&4d&4c&4d\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two perspectives on outer product: column and row.   \n",
    "Column (where we think of each column of the new matrix as the product of the first vector, multiplied elementwise by the corresponding element of the second vector. For example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "3\\\\\n",
    "4\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a\\\\\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "1a\\\\\n",
    "2a\\\\\n",
    "3a\\\\\n",
    "4a\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Row (where we think of each row of the new matrix as of the product of each element of the first vector with the whole second vector. For example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{bmatrix}\n",
    "1\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "a&b&c&d\\\\\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "1a&1b&1c&1d\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"complexvectors\"></a> \n",
    "       \n",
    "# Vectors with Complext Numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$i=\\sqrt{-1}$ (so that we can solve thing like $x^2 + 1 = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complex vectors are important for Fourier Transform (I hope I'll get there eventually...*sobs*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex numbers multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$z = a+ ib, z \\in \\mathbb{C}$$\n",
    "$$w = c+id, w \\in \\mathbb{C}$$\n",
    "$$zw = (a+ib)(c+id)=ac+aid+cib+i^2bd=ac+aid+cid-bd$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hermitian Transpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <th>Complex Number</th>\n",
    "        <th>Conjugate</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>$a+ib$</td>\n",
    "        <td>$a-ib$</td>\n",
    "    </tr>\n",
    "    <tr>    \n",
    "        <td>$a-ib$</td>\n",
    "        <td>$a+ib$</td>    \n",
    "    </tr>    \n",
    "    <tr>    \n",
    "        <td>$a$ (imaginary part is 0)</td>\n",
    "        <td>$a$</td>    \n",
    "    </tr>        \n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\begin{bmatrix}\n",
    "1+3i\\\\\n",
    "-2i\\\\\n",
    "4\\\\\n",
    "-5\\\\\n",
    "\\end{bmatrix}}^H=\n",
    "{\\begin{bmatrix}\n",
    "1+3i\\\\\n",
    "-2i\\\\\n",
    "4\\\\\n",
    "-5\\\\\n",
    "\\end{bmatrix}}^*=\n",
    "\\begin{bmatrix}\n",
    "1-3i&2i&4&-5\\\\\n",
    "\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rationale for Hemitian transpose is very simple. Let's say we have a comple number $z=3+4i$. If we plot it on real-imaginary plane (x - real part, y - imaginary part), then the magnitude of the vector will be 5 (according to Pythagorean theorem). However, if we do simple dot product with traditional transpose we will not get $5^2$: \n",
    "\n",
    "$$[3+4i]^T*[3+4i]=9+12i+12i+16i^2=9+24i-16=-7+24i$$\n",
    "\n",
    "Note: here the transpose doesn't change anything since we have a vector with just one element. \n",
    "However, if we make Hermitian transpose, it starts to make sense: \n",
    "\n",
    "$$[3+4i]^H*[3+4i]=[3-4i]*[3+4i]=9+12i-12i-16i^2=9+16=25$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.+0.j 0.+4.j 5.+2.j 2.-5.j]\n",
      "[3.+0.j 0.+4.j 5.+2.j 2.-5.j]\n",
      "[3.-0.j 0.-4.j 5.-2.j 2.+5.j]\n"
     ]
    }
   ],
   "source": [
    "v = np.array( [ 3, 4j, 5+2j, np.complex(2,-5) ] )\n",
    "print( v.T )\n",
    "print( np.transpose(v) )\n",
    "print( np.transpose(v.conjugate()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unit Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unit vector is a vector $\\mu v$ such that: \n",
    "$$\\lVert \\mu v \\rVert = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can state that: \n",
    "$$\\mu = \\frac{1}{\\lVert v \\rVert}$$, which follows from: \n",
    "$$\\lVert \\mu v \\rVert = \\frac{1}{\\lVert v \\rVert} {\\lVert v \\rVert} = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "We can also notice that we can rewrite the dot product as follows: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$v_1^T v_2 = \\lVert v_1 \\rVert \\lVert v_2 \\rVert \\cos (v_1, v_2)$$\n",
    "\n",
    "Now if we divide both parts by vector norms for $v_1$ and $v_2$ (we're allowed to do so because magnitudes are scalars): \n",
    "\n",
    "$$\\frac{v_1^T v_2}{\\lVert v_1 \\rVert \\lVert v_2 \\rVert} =  \\cos (v_1, v_2)$$\n",
    "\n",
    "This expression is also known as cosine similarity (Pearson's correlation) and has various applicatons in maching learning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"spaces\"></a>\n",
    "# Spaces and Subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field (space) is a set on which addition, subtraction, multiplication and division are valid operations. Examples:   \n",
    "- $\\mathbb{R}$ - real,   \n",
    "- $\\mathbb{C}$ - complex,  \n",
    "- $\\mathbb{Z}$ - integers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subspace** is the set of all vectors that can be created by taking linear combinations of some vector or set of vectors. Examples: \n",
    "- $\\lambda v; \\lambda \\in \\mathbb{R}$  \n",
    "- $\\lambda v + \\beta \\omega; \\lambda, \\beta \\in \\mathbb{R}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A vector subspace must:   \n",
    "- be closed under addition and scalar multiplication  \n",
    "- contain the zero vector. \n",
    "\n",
    "Or, more formally:  \n",
    "\n",
    "$$\\forall v, \\omega \\in V, \\forall \\lambda, \\alpha \\in \\mathbb{R}; \\lambda v + \\alpha \\omega \\in V$$\n",
    "\n",
    "Reads: for all $v$ and $\\omega$ that are in the subspace $V$ and for all $\\lambda$ and $\\alpha$ that are real numbers, all their linear combinations defined as $\\lambda v + \\alpha \\omega$ must stay in $V$. This covers the case with the zero vector as well - we just need to set $\\lambda$ and $\\alpha$ to 0. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:  \n",
    "$$\\lambda{\\begin{bmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "4\\\\\n",
    "\\end{bmatrix}}, \\mu{\\begin{bmatrix}\n",
    "2\\\\\n",
    "1\\\\\n",
    "4\\\\\n",
    "\\end{bmatrix}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two vectors span a plan that goes infinitely long and **passes through the origin** (-> the subspace contains the zero vector). There can be infinitely many such subspaces spanned by differen vector pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ambient ND is the space that contains all possible subspaces. For example, for Ambient 3D it will contain:   \n",
    "- 0D subspace (exactly one). \n",
    "- 1D subspace (infinitely many, because we can have infinitely many lines that go through the origin. \n",
    "- 2D subspace (inifinitely many, because we can have infinitely many planes that go through the origin.  \n",
    "- 3D subspace (exactly one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More vectore $\\neq$ more dimensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example in $\\mathbb{R}^5$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{0D:} \\Big\\{ \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}\\Big\\}, \\text{1D:} \\Big\\{ \\lambda \\begin{bmatrix}\n",
    "0\\\\\n",
    "1\\\\\n",
    "3\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix} \\Big\\}, \\text{2D:} \\Big\\{\\alpha \\begin{bmatrix}\n",
    "0\\\\\n",
    "1\\\\\n",
    "3\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\beta \\begin{bmatrix}\n",
    "9\\\\\n",
    "4\\\\\n",
    "2\\\\\n",
    "3\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}\\Big\\}, \\\\ \\text{Still 2D:} \\Big\\{\\alpha \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}, \\beta \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\gamma \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "2\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}\\Big\\}, \\text{3D:} \\Big\\{\\alpha \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}, \\beta \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\gamma \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}\\Big\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subspace vs Subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subset** - a set of points that satifly some conditions. It doesn't need to be closed or include the origin, and that is the key different from a **subspace**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples\n",
    "1) All points on XY plane such that $x>0, y > 0$. Subset, but **NOT** a subspace because if we multiply a vector in that subset by -1, we will be out of this subset. Hence, it's not a subspace.   \n",
    "\n",
    "2) All points on XY plane such that $x^2 + y^2 = 0$. Subset, but **NOT** a subspace, because it doesn't even contain the origin.  \n",
    "\n",
    "3) All points in XY such that $y=4x, \\forall x$. Subset and subspace. Goes through the origin. No matter what scalar we take, we're still on that line.   \n",
    "\n",
    "4) All points in XY such that $y=4x+1, \\forall x$. Subset, but **NOT** a subspace. It doesn't go through the origin.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we can see that the basic method to define if a subset is also a subspace is as follows: \n",
    "- Determine whether the origin is in the set. \n",
    "- Try to write down the critera in terms of scalars and vectors of the form $\\alpha v + \\beta \\omega$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"span\"></a>\n",
    "# Span\n",
    "Span - entire space that can be reached by linear combination of the vectors. The same span can be formed by DIFFERENT sets of vectors - they will span the same space, but we will use different coefficients. Some of them are just more convinient in certain cases (for example, for eigendecomposition)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\text{span}(\\{v_1, ..., v_n\\}) = \\{\\alpha_1 v_1 + ... \\alpha_n v_n, \\alpha_i \\in \\mathbb{R} \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:  \n",
    "$$v = \\begin{bmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\omega = \\begin{bmatrix}\n",
    "3\\\\\n",
    "2\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}, S = \\Big\\{ \\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "1\\\\\n",
    "7\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}  \\Big\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$v$ is in the span of S, because we can get exactly this vector by taking 5/6 of the first vector of S and 1/6 of the second. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very important example of when different span can be more convenient. Let's, say we have two spans: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S_1 = \\Big\\{ \\begin{bmatrix}\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}  \\Big\\}, S_2 = \\Big\\{ \\begin{bmatrix}\n",
    "-3/2\\\\\n",
    "-1/2\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "-1/2\\\\\n",
    "-1/2\\\\\n",
    "\\end{bmatrix}  \\Big\\}$$  \n",
    "\n",
    "The first span is standard XY plan - Cartesian coordinate system with orthogonal vectors in the basis. So if have a vector $v$ that is defined as $[3/2, 1/2]$ in $S_1$, we can actually get a nicer version of it by switching to $S_2$, where it will be just $[-1,0]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"linindep\"></a>\n",
    "# Linear Independence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formal defintion:  \n",
    "The vectors are linearly dependent if there is a linear combination, such that:  \n",
    "\n",
    "$$\\lambda_1 v_1 + \\lambda_2 v_2 + ... + \\lambda_n v_n = 0, \\lambda_i \\in \\mathbb{R}, \\exists \\lambda_i \\neq 0$$ \n",
    "\n",
    "(i.e. excluding the case when all lambdas are zero - trivial solution). \n",
    "\n",
    "**A set of M vectros is independent if each vector points in a geometric dimension not reachable using other vectors in the set.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More informally: vectors are linearly dependent if one or more vectors can be expressed using other vectors. \n",
    "**Checking for linear independence:** \n",
    "- Step 1: Count vectors and comper with $\\mathbb{R}^N$ (>N -> dependent) \n",
    "- Step 2: Check for 0s in corresponding dimensions. Also, if 0 vector is in the set -> dependent\n",
    "- Educated guess and test (try to get a linear combination)  \n",
    "- Matrix rank method \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples: \n",
    "\n",
    "1) $\\{ \\omega_1, \\omega_2 \\} = \\Big\\{ \\begin{bmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "3\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "2\\\\\n",
    "4\\\\\n",
    "6\\\\\n",
    "\\end{bmatrix}  \\Big\\}$ - linearly dependent, because $\\omega_2 = 2 \\omega_1$  \n",
    "\n",
    "2) $\\{ v_1, v_2, v_3 \\} = \\Big\\{ \\begin{bmatrix}\n",
    "0\\\\\n",
    "2\\\\\n",
    "5\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "-27\\\\\n",
    "5\\\\\n",
    "-37\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "3\\\\\n",
    "1\\\\\n",
    "8\\\\\n",
    "\\end{bmatrix} \\Big\\}$ - linearly dependent, because $v_2=7 v_1 - 9 v_3$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theorem: Maximum N independent vectors in $\\mathbb{R}^N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Any set of $M>N$ vectors in $\\mathbb{R}^N$ is **dependent**  \n",
    "- Any set of $M<=N$ vectors in $\\mathbb{R}^N$ **could be independent**  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = \"basis\"></a>\n",
    "# Basis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of vectors can form a **basis** for some subspace if that set spans that subspace and if it contains linearly independent vectors. \n",
    "\n",
    "Examples of basis: \n",
    "\n",
    "$$\\mathbb{R}^2: S = \\Big\\{ \\begin{bmatrix}\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix} \\Big\\}$$\n",
    "\n",
    "$$\\mathbb{R}^3: L = \\Big\\{ \\begin{bmatrix}\n",
    "1\\\\\n",
    "0\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0\\\\\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0\\\\\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix} \\Big\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis for $\\mathbb{R}^2$ shown above is not the only one to define the same space. We can also define it as: \n",
    "\n",
    "$$T = \\Big\\{ \\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}, \\begin{bmatrix}\n",
    "0\\\\\n",
    "2\\\\\n",
    "\\end{bmatrix} \\Big\\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we have a point in S, that is expressed as $(2,1)$, we can express it in T as $(2,-\\frac{1}{2})$. Looks worse, right? But for the point $(3,3)$ in S we will get a more compact representation with T: $(3,0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important:**  \n",
    "We **CAN'T** have *extra* vectors in the basis because that we'll more than one way to identify a vector in that span. However, if don't have *redundant* vectors, we can uniquely identify a vector. \n",
    "There are $\\infty$ number of bases but they all must contain only linearly independent vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
