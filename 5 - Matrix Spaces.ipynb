{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matrix Spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This text and code is derived from Mike X Cohen's course on linear algebra. For more information, see https://www.udemy.com/linear-algebra-theory-and-implementation/?couponCode=LINALGPX7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column Space of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notation: column space is denoted as $C(\\mathbf{A})$ \n",
    "\n",
    "$C(\\mathbf{A})$ is the vector space that is spanned by all of the columns in a matrix. However, these columns **don't have to be a basis**.\n",
    "\n",
    "Formally, the column space is defined as: \n",
    "\n",
    "$$C(\\mathbf{A}) = \\{\\beta_1 \\mathbf{a_1} + ... + \\beta_n \\mathbf{a_n} \\}, \\beta \\in \\mathbb{R}$$\n",
    "\n",
    "$$C(\\mathbf{A}) = span(\\mathbf{a_1} + ... \\mathbf{a_n})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretation: all possible linear combinations of all the columns in the matrix. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is v in C(A)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important questions in linear algebra is whether a vector **v** is in the column space of matrix A? The answer to this questions lead to another questions: \n",
    "\n",
    "### If $\\mathbf{v}$ is in $C(\\mathbf{A})$, then what are the coefficients?   \n",
    "\n",
    "This questions could be answered with an equation: \n",
    "\n",
    "$$\\mathbf{A w} = \\mathbf{v}$$\n",
    "\n",
    "It tells us that v can be constructed from the columns of $\\mathbf{A}$ using the weights $\\mathbf{w}$\n",
    "\n",
    "### If $\\mathbf{v}$ is not in $C(\\mathbf{A})$, then how to get as close as possible to that column space? \n",
    "\n",
    "In other words, what coefficients will allow us to minimize the distance? \n",
    "\n",
    "For starters, we can write it as follows: \n",
    "\n",
    "$$\\mathbf{A w} - \\mathbf{v} = \\mathbf{z}$$,\n",
    "\n",
    "where $\\mathbf{z}$ is some non-zero vector. We can take the magnitued of both sides: \n",
    "\n",
    "$$||\\mathbf{A w} - \\mathbf{v}|| = ||\\mathbf{z}||$$,\n",
    "\n",
    "and then set the objective to minimize that. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Row Space of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$R(\\mathbf{A})$ is the subspace spanned by the rows of A. \n",
    "Notation: $R(\\mathbf{A})$ OR $C(\\mathbf{A^T})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column space: $\\mathbf{A w} = \\mathbf{v}$\n",
    "\n",
    "Row space: $\\mathbf{w A} = \\mathbf{v}$ (of course, $\\mathbf{w}$ and $\\mathbf{v}$ are both row vectors in this case). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**. \n",
    "\n",
    "Let's say we have data from N sensors measured at certain time intervals, so there are M observations (each containing data from all sensors - so, N values). That gives us an M by N matrix. \n",
    "If we take the column space - $\\mathbf{A w}$, we will have the combination of sensors (and if $\\mathbf{w}$ is filter, then we will have spatial filtering). \n",
    "If we take the row space - $\\mathbf{w a}$ and $\\mathbf{w}$ is a filter, then we will have temporal filtering. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Space and Left-Null Spade of a Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition: \n",
    "$N(\\mathbf{A})$ is the set of all vectors $\\{ \\mathbf{v} \\}$ such that $\\mathbf{A v = 0}$ and $\\mathbf{v \\neq 0}$   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Examples** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\begin{bmatrix}\n",
    "1&1\\\\\n",
    "2&2\\\\\n",
    "\\end{bmatrix}}$, $r(\\mathbf{A}) = 1$, $N(\\mathbf{A}) = \\{ \\lambda {\\begin{bmatrix}\n",
    "1\\\\\n",
    "-1\\\\\n",
    "\\end{bmatrix}} \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\begin{bmatrix}\n",
    "1&1\\\\\n",
    "2&1\\\\\n",
    "\\end{bmatrix}}$, $r(\\mathbf{A}) = 2$, $N(\\mathbf{A}) = \\{ \\}$ (nullspace is the empty set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "${\\begin{bmatrix}\n",
    "0&0\\\\\n",
    "0&0\\\\\n",
    "\\end{bmatrix}}$, $r(\\mathbf{A}) = 0$, $N(\\mathbf{A}) = \\{ \\lambda_1 {\\begin{bmatrix}\n",
    "0\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}}, \\lambda_2 {\\begin{bmatrix}\n",
    "1\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}} \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Left null space definiton: $N(\\mathbf{A^T})$ is the set of all vectors $\\{\\mathbf{v}\\}$ such that $\\mathbf{v^T A = 0^T}$ and $\\mathbf{v^T \\neq 0^T}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**\n",
    "\n",
    "Let $A = {\\begin{bmatrix}\n",
    "a&b\\\\\n",
    "c&d\\\\\n",
    "\\end{bmatrix}}$\n",
    "\n",
    "If $\\mathbf{v} \\notin N(\\mathbf{A})$, then left-multiplying this vector by some compatible transformation matrix will produce some other vector in that space (provided, it's not in the null space of any of these transformation matrices).\n",
    "\n",
    "If $\\mathbf{v} \\in N(\\mathbf{A})$, then no matter what transformation matrices we have, it will produce $\\mathbf{0}$. So, it's like blackhole! (Special thanks to Mike X Cohen for that awesome analogy). :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogonality of Column/Left-null Space and Row/Null Spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick recap: \n",
    "\n",
    "Orthogonality of vectors can be established when their dot product is equal to 0 (means that the angle between them is 90, so the cosine is 0): \n",
    "\n",
    "$$ \\alpha = \\mathbf{a^T b} = ||\\mathbf{a}|| ||\\mathbf{b}|| \\cos(\\theta_{\\mathbf{ab}}) = 0 \\implies \\mathbf{a \\perp b}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we say that a vector is orthogonal to a colum space (i.e. $\\mathbf{v} \\perp C(\\mathbf{A})$), we mean that: \n",
    "\n",
    "$$\\mathbf{v^T} \\{\\alpha_1 \\mathbf{a_1} + \\alpha_2 \\mathbf{a_2} + ... + \\alpha_n \\mathbf{a_n}\\} = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, vector $\\mathbf{v}$ is orthogonal to any possible linear combination of the columns of A."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, recall the definition of the left-null space:\n",
    "\n",
    "$$\\mathbf{v^T A = 0^T}$$\n",
    "\n",
    "We can transpose both sides and rewrite it as: \n",
    "\n",
    "$$\\mathbf{A^T v = 0}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector $\\mathbf{v}$ is orthogonal to each and every column in $\\mathbf{A}$ (or row in $\\mathbf{A^T}$). So, we can say that left-null space is orthogonal to the column space of $\\mathbf{A}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To summarize:\n",
    "\n",
    "$$N(\\mathbf{A^T}) \\perp C(\\mathbf{A})$$    \n",
    "\n",
    "$$N(\\mathbf{A}) \\perp R(\\mathbf{A})$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Dimensions of Column/Row/Null Spaces "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**\n",
    "\n",
    "$\\mathbf{A} = {\\begin{bmatrix}\n",
    "1&1\\\\\n",
    "2&2\\\\\n",
    "\\end{bmatrix}}$, $\\mathbf{A^T} = {\\begin{bmatrix}\n",
    "1&2\\\\\n",
    "1&2\\\\\n",
    "\\end{bmatrix}}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ambient dimensionality is 2 (we take N M-dimensional vectors)\n",
    "$N(\\mathbf{A^T}) = \\{ \\lambda {\\begin{bmatrix}\n",
    "-2\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}} \\}$, $N(\\mathbf{A^T}) \\perp C(\\mathbf{A})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column space and the left-null space toghter must span the whole ambient space (full dimensionality) $\\implies$\n",
    "\n",
    "$$\\dim(C(\\mathbf{A})) + \\dim(N(\\mathbf{A^T})) = M$$\n",
    "\n",
    "$$\\dim(C(\\mathbf{A^T})) + \\dim(N(\\mathbf{A})) = N$$\n",
    "\n",
    "for $\\mathbf{A} \\in \\mathbb{R}^{M \\times N}$. Note that columns are in $\\mathbb{R}^M$ and rows are in $\\mathbb{R}^N$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of the Four Subspaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $\\mathbf{A} \\in \\mathbb{R}^{M \\times N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ambient spaces for $\\mathbf{A}$: \n",
    "\n",
    "- $\\mathbb{R}^M: C(\\mathbf{A}) \\cup N(\\mathbf{A^T})$ (together span the whole $\\mathbb{R}^M$. \n",
    "- $\\mathbb{R}^N: R(\\mathbf{A}) \\cup N(\\mathbf{A})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**  \n",
    "\n",
    "$\\mathbf{A} = {\\begin{bmatrix}\n",
    "1&2&0\\\\\n",
    "3&3&-3\\\\\n",
    "\\end{bmatrix}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Column space of $\\mathbf{A}$* \n",
    "\n",
    "$$ C(\\mathbf{A}) = \\{ {\\begin{bmatrix}\n",
    "1\\\\\n",
    "3\\\\\n",
    "\\end{bmatrix}}, {\\begin{bmatrix}\n",
    "2\\\\\n",
    "3\\\\\n",
    "\\end{bmatrix}}\\} \\in \\mathbb{R}^2$$ (as any two vectors out of three would do)\n",
    "\n",
    "$$\\dim(C(\\mathbf{A}))=2$$\n",
    "\n",
    "Other ways to define the column space: \n",
    "\n",
    "$$ C(\\mathbf{A}) = span( \\{ {\\begin{bmatrix}\n",
    "1\\\\\n",
    "3\\\\\n",
    "\\end{bmatrix}}, {\\begin{bmatrix}\n",
    "2\\\\\n",
    "3\\\\\n",
    "\\end{bmatrix}} \\}) $$\n",
    "\n",
    "$$ C(\\mathbf{A}) = \\lambda {\\begin{bmatrix}\n",
    "1\\\\\n",
    "3\\\\\n",
    "\\end{bmatrix}} + \\beta {\\begin{bmatrix}\n",
    "2\\\\\n",
    "3\\\\\n",
    "\\end{bmatrix}}, \\lambda, \\beta \\in \\mathbb{R}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Row space of $\\mathbf{A}$*\n",
    "\n",
    "$$R(\\mathbf{A}) = \\{ {\\begin{bmatrix}\n",
    "1\\\\\n",
    "2\\\\\n",
    "0\\\\\n",
    "\\end{bmatrix}}^T, {\\begin{bmatrix}\n",
    "3\\\\\n",
    "3\\\\\n",
    "-3\\\\\n",
    "\\end{bmatrix}}^T\\} \\in \\mathbb{R}^3$$\n",
    "\n",
    "\n",
    "$$\\dim(R(\\mathbf{A}))=2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Left-null space of $\\mathbf{A}$*\n",
    "\n",
    "$$N(\\mathbf{A^T}) = \\{ \\} \\in \\mathbb{R}^2$$ (an empty set)\n",
    "\n",
    "\n",
    "$$\\dim(N(\\mathbf{A^T}))=0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Null Space of $\\mathbf{A}$*\n",
    "\n",
    "We know that the null space should be orthogonal to the row space - to every row vector. So we need to find a vector such that the dot product of this vector with any of the vectors in the row space produces zero. \n",
    "We can find the first two coordinates from the first row: let them be 2 and -1. Now, to produce zero with the second row, we need to set the third coordinate to 1. Thus, the null space is: \n",
    "\n",
    "$$N(\\mathbf{A^T}) = \\{ {\\begin{bmatrix}\n",
    "2\\\\\n",
    "-1\\\\\n",
    "1\\\\\n",
    "\\end{bmatrix}}^T \\} \\in \\mathbb{R}^3$$\n",
    "\n",
    "\n",
    "$$\\dim(N(\\mathbf{A}))=1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ax = b and Ax = 0 Revisited "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some alternative notations: \n",
    "- We can safely rewrite $\\mathbf{A x = b}$ as $\\mathbf{A X = B}$, where $\\mathbf{X}$ and $\\mathbf{B}$ are Nx1 matrices. \n",
    "- In statistics it's often $\\mathbf{X} \\beta = \\mathbf{y}$, where we look for $\\beta$ rather than $\\mathbf{X}$. Here, $\\mathbf{X}$ is the desing matrix, $\\mathbf{y}$ is the observed data and $\\beta$ are regression coefficients. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\mathbf{A x = b}$ has a solution if $b \\in C(\\mathbf{A})$. And when $b \\notin C(\\mathbf{A})$, we're interested in finding the closest solution: \n",
    "\n",
    "$$\\mathbf{A \\hat{x} = \\hat{b}}$$,\n",
    "($\\hat{\\mathbf{b}}$ is chosen such that $\\hat{\\mathbf{b}} \\in C(\\mathbf{A})$), and we're minimizing $||\\mathbf{\\hat{b}-b}||$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for $\\mathbf{A x = 0}$, we often want to solve: \n",
    "$(\\mathbf{A} - \\lambda \\mathbf{I}) \\mathbf{x = b}$, where $\\lambda$ is the eigenvalue and $\\mathbf{x}$ is the eigenvector. The solution to this equation is used for PCA, SVD, FDA, etc. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
